{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from scripts.dataset import ImgDataset, readLabel, readImg\n",
    "from scripts.models import DG_model, Discriminator, Feature_Generator_ResNet, Classifier\n",
    "from scripts.utils import auc_acc\n",
    "from scripts.hard_triplet_loss import HardTripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_dir = '../../final_project/data/oulu_npu_cropped'\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=30),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = True\n",
    "bs = 60\n",
    "train_folder = os.path.join(workspace_dir,'train_rembg')\n",
    "phones, sess, ids, train_y = readLabel(train_folder, order='single', binary=binary)\n",
    "train_x_rembg = np.load(os.path.join(workspace_dir,'train_x_rembg.npy'))\n",
    "train_x_orig = np.load(os.path.join(workspace_dir,'train_x.npy'))\n",
    "train_x = np.concatenate([train_x_orig, train_x_rembg])\n",
    "train_dataset = ImgDataset(train_x, np.tile(train_y,(2)), np.tile(sess,(2)), train_transform, 'single', binary)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "val_folder = os.path.join(workspace_dir,'val')\n",
    "val_x = np.load(os.path.join(workspace_dir,'val_x.npy'))\n",
    "phones, sess, ids, val_y = readLabel(os.path.join(workspace_dir,'val'), order='single', binary=binary)\n",
    "val_set = ImgDataset(val_x, val_y, sess, test_transform, 'single', binary)\n",
    "val_loader = DataLoader(val_set, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DG_model(model = 'resnet18', num_cls = (1 if binary else 3)).cuda()\n",
    "domain_classifier = Discriminator(num_cls=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = {'class': (nn.BCELoss().cuda() if binary else nn.CrossEntropyLoss().cuda()),\n",
    "             'triplet': HardTripletLoss(margin=0.1, hardest=False).cuda(),\n",
    "             'domain': nn.CrossEntropyLoss().cuda()}\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-4, weight_decay=1e-5)  # optimizer 使用 Adam\n",
    "optimizer_D = torch.optim.Adam(domain_classifier.parameters(),lr=1e-5, weight_decay=1e-4)  # optimizer 使用 Adam\n",
    "num_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_coef = 1.0\n",
    "sess_coef = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:12<00:00, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/001] 12.35 sec(s) Train Acc: 0.818447 Train AUC: 0.785311 Train  loss: 0.000000 D_loss: 0.000000\n",
      "                        cls  loss: 0.000000 trip loss: 0.000000 domain loss: 0.000000\n",
      "                        Valid Acc: 0.890202 Valid AUC: 0.935827 Valid  loss: 0.269006 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    triplet_loss = 0.0\n",
    "    domain_loss_total = 0.0\n",
    "    cls_loss_total = 0.0\n",
    "    val_loss = 0.0\n",
    "    running_D_loss = 0.0\n",
    "    model.train()  # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "    train_logits = []\n",
    "    train_labels = []\n",
    "    for data, label, sess in tqdm(train_dataloader):\n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "        sess = sess.cuda()\n",
    "        domain_label = sess\n",
    "        # train domain classifier\n",
    "        pred, feature = model(data.cuda())\n",
    "        domain_logits = domain_classifier(feature.detach())\n",
    "\n",
    "        loss = criterion['domain'](domain_logits, domain_label)\n",
    "        running_D_loss+= loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_D.step()\n",
    "        # train main model\n",
    "        pred, feature = model(data.cuda())\n",
    "        class_logits = pred[:data.shape[0]]\n",
    "        domain_logits = domain_classifier(feature)\n",
    "\n",
    "        cls_loss = criterion['class'](class_logits.squeeze(), label)\n",
    "        triplet = criterion[\"triplet\"](feature, label)\n",
    "        domain_loss = criterion['domain'](domain_logits, domain_label)\n",
    "\n",
    "        loss =  cls_loss + triplet_coef*triplet + sess_coef*domain_loss\n",
    "        cls_loss_total += cls_loss.item()\n",
    "        triplet_loss += triplet_coef*triplet \n",
    "        domain_loss_total += sess_coef*domain_loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()  # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "        optimizer.zero_grad()  # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "        optimizer_D.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        train_logits.append(class_logits)\n",
    "        train_labels.append(label)\n",
    "\n",
    "    train_auc, train_acc = auc_acc(torch.cat(train_logits), torch.cat(train_labels), binary)\n",
    "    model.eval()\n",
    "    val_logits = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label, sess in tqdm(val_loader):\n",
    "            class_logits, embedded = model(data.cuda())\n",
    "            batch_loss = criterion['class'](class_logits, label.cuda())\n",
    "            val_logits.append(class_logits)\n",
    "            val_labels.append(label)\n",
    "            val_loss += batch_loss.item()\n",
    "        val_auc, val_acc = auc_acc(torch.cat(val_logits), torch.cat(val_labels), binary)\n",
    "\n",
    "        running_D_loss /= train_dataloader.__len__()\n",
    "        train_loss /= train_dataloader.__len__()\n",
    "        cls_loss_total /= train_dataloader.__len__()\n",
    "        triplet_loss /= train_dataloader.__len__()\n",
    "        domain_loss_total /= train_dataloader.__len__()\n",
    "        val_loss /= val_loader.__len__()\n",
    "        print('[{:03}/{:03}] {:3.2f} sec(s) Train Acc: {:.6f} Train AUC: {:.6f} Train  loss: {:3.6f} D_loss: {:3.6f}'\\\n",
    "            .format(epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc, train_auc, train_loss, running_D_loss))\n",
    "        print(' '*24+'cls  loss: {:3.6f} trip loss: {:3.6f} domain loss: {:3.6f}'\\\n",
    "            .format(cls_loss_total, triplet_loss, domain_loss_total ))\n",
    "        print(' '*24+'Valid Acc: {:.6f} Valid AUC: {:.6f} Valid  loss: {:3.6f} '\\\n",
    "            .format(val_acc, val_auc, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('dlcv')",
   "language": "python",
   "name": "python36864bitdlcv12f122213a8b4d8fb394fdf265822007"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
